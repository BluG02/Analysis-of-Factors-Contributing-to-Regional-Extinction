import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.model_selection import KFold
from sklearn.metrics import r2_score, mean_squared_error
import matplotlib.pyplot as plt

def build_and_evaluate_model(file_path):
    # 1. ë°ì´í„° ë¡œë“œ
    df = pd.read_excel(file_path)
    
    # 2. í”¼ì²˜ ë° íƒ€ê²Ÿ ì„¤ì •
    target = "ì¸êµ¬ì†Œë©¸ì§€ìˆ˜"
    X = df.select_dtypes(include=["number"]).drop(columns=[target])
    y = df[target]

    # 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    X = X.fillna(X.mean())
    y = y.fillna(y.mean())

    # 4. ëª¨ë¸ ì •ì˜ (íŠœë‹ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°)
    model = XGBRegressor(
        subsample=0.6,
        n_estimators=300,
        max_depth=5,
        learning_rate=0.05,
        colsample_bytree=0.8,
        random_state=42
    )

    # 5. êµì°¨ê²€ì¦ ì„¤ì •
    kf = KFold(n_splits=5, shuffle=True, random_state=42)

    # 6. êµì°¨ê²€ì¦ ìˆ˜ë™ ìˆ˜í–‰
    r2_list, mse_list, rmse_list = [], [], []

    for train_idx, val_idx in kf.split(X):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

        model.fit(X_train, y_train)
        y_pred = model.predict(X_val)

        r2 = r2_score(y_val, y_pred)
        mse = mean_squared_error(y_val, y_pred)
        rmse = np.sqrt(mse)

        r2_list.append(r2)
        mse_list.append(mse)
        rmse_list.append(rmse)

    # 7. í‰ê°€ ì¶œë ¥
    print(" Foldë³„ RÂ²:", np.round(r2_list, 4))
    print(" Foldë³„ MSE:", np.round(mse_list, 6))
    print(" Foldë³„ RMSE:", np.round(rmse_list, 4))
    print(f"\nğŸ“ˆ í‰ê·  RÂ²: {np.mean(r2_list):.4f}")
    print(f" í‰ê·  MSE: {np.mean(mse_list):.6f}")
    print(f" í‰ê·  RMSE: {np.mean(rmse_list):.4f}")

    # ì „ì²´ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ
    model.fit(X, y)
    return model, X  # ìµœì¢… ëª¨ë¸ê³¼ í”¼ì²˜ ìˆœì„œ ë°˜í™˜

# ğŸ”® ì‚¬ìš©ì ì…ë ¥ ê¸°ë°˜ ì˜ˆì¸¡ í•¨ìˆ˜
def predict_new(model, X_columns, region_data: dict):
    input_df = pd.DataFrame([region_data])
    input_df = input_df[X_columns]  # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
    predicted_value = model.predict(input_df)[0]
    print(f"\n ì˜ˆì¸¡ëœ ì¸êµ¬ì†Œë©¸ì§€ìˆ˜: {predicted_value:.4f}")
    return predicted_value

def show_feature_importance(model, feature_names):
    importances = model.feature_importances_
    importance_df = pd.DataFrame({
        'Feature': feature_names,
        'Importance': importances
    }).sort_values(by='Importance', ascending=False)


    plt.figure(figsize=(8, 6))
    plt.barh(importance_df['Feature'][:10][::-1], importance_df['Importance'][:10][::-1])
    plt.xlabel("Importance Score")
    plt.title("ğŸ” XGBoost Feature Importance (Top 10)")
    plt.tight_layout()
    plt.show()

# ğŸ§ª ì‹¤í–‰ ì˜ˆì‹œ
def main():
    model, X = build_and_evaluate_model("ìµœì¢…_í†µí•©_2018_2021_ìš”ì–‘í¬í•¨.xlsx")

    # ì˜ˆì‹œ ì…ë ¥ê°’
    example_region = {
        'í•©ê³„ì¶œì‚°ìœ¨': 1.09,
        'ì„±ë¹„': 105.41,
        'ê³ ë ¹ì¸êµ¬ë¹„ìœ¨': 10, #23.53 -> 10 
        'ì¸êµ¬ì‹­ë§Œëª…ë‹¹ ë¬¸í™”ê¸°ë°˜ì‹œì„¤ ìˆ˜': 15.89,
        'ì¸êµ¬10ë§Œëª…ë‹¹ ì‚¬íšŒë³µì§€ì‹œì„¤ìˆ˜': 41.3,
        'ì¬ì •ìë¦½ë„': 50, #25.7 -> 50
        'ì´ˆë“±í•™êµ ìˆ˜': 13,
        'ì „ë¬¸ëŒ€í•™ ë° ëŒ€í•™êµ ìˆ˜': 0,
        'ì—°ë„': 2018,
        'ìš”ì–‘ê¸°ê´€ ìˆ˜_ì „ì²´': 197.0361
    }
    import matplotlib.font_manager as fm
    import platform

    plt.rcParams['font.family'] = 'Malgun Gothic'  # ë§‘ì€ ê³ ë”•
    plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
    show_feature_importance(model, X.columns.tolist())

    predict_new(model, X.columns.tolist(), example_region)


# ğŸš€ ì‹¤í–‰
if __name__ == "__main__":
    main()